# LLM (Large Language Model) Reading List
A 2023 Edition of LLM reading list to get up to date on current research and trends. 

# Large Language Models 
- GPT-2 -> [Large Language Models are Unsupervised Multitask Learners](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)
- GPT-3 -> [Large Language Models are Few shot Learners](https://arxiv.org/pdf/2005.14165.pdf)


# Meta LLM papers 
- [Emergent Abilities of Large Language Models](https://arxiv.org/abs/2206.07682)


# Prompting Research
## Chain of Thought prompting
- [Chain of Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/abs/2201.11903)
- Self Consistency Decoding Strat + CoT -> [Self-Consistency Improves Chain of Thought Reasoning in Language Models](https://arxiv.org/abs/2203.11171)
- Zero-Shot CoT -> [Large Language Models are Zeroshot Reasoners](https://arxiv.org/abs/2205.11916)
- CoT performance on Big Bench -> [Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them](https://arxiv.org/abs/2210.09261)
- CoT performance on Multilingual Math Word Problems -> [Language Models are Multilingual Chain-of-Thought Reasoners](https://arxiv.org/abs/2210.03057)
- [Automatic Chain of Thought Prompting in Large Language Models](https://arxiv.org/abs/2210.03493)
- [Towards Understanding Chain-of-Thought Prompting: An Empirical Study of What Matters](https://arxiv.org/pdf/2212.10001.pdf)
- [Active Prompting with Chain-of-thought for Large Language Models](https://arxiv.org/abs/2302.12246)



## ScratchPad prompting
- [Show your Work: Scratchpads for Intermediate Computation with Language Models](https://arxiv.org/pdf/2112.00114.pdf)
- [Learning by Distilling Context](https://arxiv.org/abs/2209.15189?)

## Other strategies 
- Least-to-Most Prompting -> [Least-to-Most Prompting Enables Complex Reasoning in Large Language Models](https://arxiv.org/abs/2205.10625)
